extends layouts/_layout

block slides
  +slide
    .title End-to-end Driving via Conditional Imitation Learning
    .info Felipe Codevilla, Matthias Müller, Alexey Dosovitskiy, Antonio López, and Vladlen Koltun, arXiv 1710.02410
    .item1
      h1 概要
      .text.
        自動運転を模倣学習により行う手法を提案。実空間での学習結果をヴァーチャルな空間での自動運転にて再現することができた。RGB画像、計測（e.g. スピード）や命令（e.g. turn right）などからステアリング、アクセル、ブレーキなどのコマンドを出力して自動車を操作する。
    .item2
      img(src=figpath+"180205conditionalimitationlearning.png")
      img(src=figpath+"180205framework_imitation.png")
    .item3
      h1 新規性・結果
      .text
        ul
          li 模倣学習による自動運転を実現した。
          li 実空間とシミュレーションベースの転移を行うことにも成功。
    .item4
      h1 リンク集
      .text
        ul
          li 自動運転の学習はシミュレーションベースで完結してしまう可能性がある。
          li メタ学習/模倣学習/強化学習などはCVに徐々に取り入れられてくるはずなので、2018年は学習しておいて損はない？
          li: a(href="https://arxiv.org/pdf/1710.02410.pdf" target="blank") [論文] End-to-end Driving via Conditional Imitation Learning
          li: a(href="https://www.youtube.com/watch?v=cFtnflNe5fM" target="blank") YouTube
          li: a(href="http://hirokatsukataoka.net/" target="blank") slide by Hirokatsu Kataoka
    .header
      | #{getPaperIndex()}

  +slide
    .title Open3D: A Modern Library for 3D Data Processing
    .info Qian-Yi Zhou et al., arXiv 1801.09847
    .item1
      h1 概要
      .text
        |3Dデータを取り扱い、迅速な開発を可能にする
        a(href="http://www.open3d.org/" target="blank") Open3D
        |を提供する。Open3DはC++/Pythonをサポート、並列化にも対応しており、クラウドで開発することが可能。
        |点群読み込み-ダウンサンプリング-法線の計算、シーン再構築、3次元可視化などの処理が含まれている。
    .item2
      img(src=figpath+"180205open3d.png")
    .item3
      h1 新規性・結果
      .text
        |3次元画像処理のコミュニティにて有益なオープンソースを提供し、その
        a(href="https://github.com/IntelVCL/Open3D" target="blank") コード
        |も提供されている。
    .item4
      h1 コメント・リンク集
      .text
        ul
          li: a(href="http://www.open3d.org/" target="blank") Project page
          li: a(href="https://arxiv.org/pdf/1801.09847.pdf" target="blank") [論文] Open3D: A Modern Library for 3D Data Processing
          li: a(href="https://github.com/IntelVCL/Open3D" target="blank") Code
          li: a(href="http://hirokatsukataoka.net/" target="blank") slide by Hirokatsu Kataoka
    .header
      | #{getPaperIndex()}

  +slide
    .title Hierarchical Variational Autoencoders for Music
    .info A. Roberts et al., NIPS WS on Machine Learning for Creativity and Design, 2017.
    .item1
      h1 概要
      .text
        | 音楽を生成するためのHierarchical Variational Autoencoders (VAE) を提案．
        | エンコーダとデコーダがLSTMで構成されているReccurent VAEがベース．
        a(href="https://goo.gl/twGuP2") 結果サンプル
        | 長い音楽（実験では32小節）を単純なLSTMデコーダで生成するのは難しいので，
        | この研究では複数のLSTMを階層的に重ねて，段階的に長くしていくHierarchical VAEを提案．
        | ループメロディの外挿や，メロディの生成，3ピース構成の音楽生成の実験で性能を検討．
        | 結果の音楽やコードは公開されている．
    .item2
      img(src=figpath+"hierarchical_vae.png")
    .item3
      h1 新規性・結果
      .text
        ul
          li 階層的なLSTMによるデコーダをVAEによる音楽生成に導入
          li
            a(href="https://goo.gl/twGuP2") 結果サンプル
    .item4
      h1 自由記述欄
      .text
        ul
          li これも長期的な構成を考えて生成することはできていない
          li Future Workにはインタフェースを作るとあるし，1曲まるごと作るというよりは適当にサンプルを出して作曲家のアイデアを促進することを目指しているのかな．
    .header
      | #{getPaperIndex()}

  +slide
    .title Generating the Future with Adversarial Transformers
    .info C. Vondrick et al., CVPR, 2017.
    .item1
      h1 概要
      .text.
        未来の動画を予測して生成する手法を提案．
        4フレーム x 64画素 x 64画素のクリップを入力として，その後の16フレームの動画を生成．
        完全に新しいフレームを生成するのは難しいので，入力フレームの変換により未来のフレームを生成するのがポイント．
        論文の主張としては，きれいな動画を作るにはLow-Levelな情報が重要だけど，未来予測のためにはHigh-Levelな理解も必要で，
        その両者を一つのネットワークで一気に学習するのは難しいとしている．
        だから，Low-Levelな情報は元のフレームを変換することで引っ張ってきて，ネットワークはHigh-Levelな特徴抽出に集中させるのが良いとのこと．
        このネットワークの学習はGANベース．
        生成動画の主観評価や可視化，Generatorの特徴を利用した物体認識タスクなどで性能を評価．

    .item2
      img(src=figpath+"generating_future.png")
    .item3
      h1 新規性・結果
      .text
        ul
          li 元のフレームからの変換により未来のフレームを生成する手法を提案
          li 未来の動画生成において，敵対的学習により大規模な教師なしデータを利用した学習を実現
          li 直接動画を生成したり，回帰誤差で学習したりする手法よりも良いことを主観評価実験で確認          
    .item4
      h1 自由記述欄
      .text
        ul
          li 入力が4フレームだけだけど，もっと増やすと性能は変わるのか気になる
          li 主観評価で本物と比較すると提案手法が一番嫌われている率が高いのもちょっと気になる
    .header
      | #{getPaperIndex()}

  +slide
    .title DensePose: Dense Human Pose Estimation In The Wild
    .info Rıza Alp Guler et al.
    .item1
      h1 概要
      .text.
        身体の表面形状まで考慮したDenseな姿勢推定手法に関する研究。サーフェイスモデルを提供するSMPLタイプとアノテーションベースのMSCOCOタイプを提供。手法はMask RCNN（w/ ResNet-50, ROI-align, Regression）をベースに構築している。

    .item2
      img(src=figpath+"180205densepose.png")
    .item3
      h1 新規性・結果
      .text
        ul
          li DenseReg [Guler,CVPR17]は顔表面の推定に対して、本研究では身体全体の表面やデンスなポイントを回帰。
          li SMPLやDense-COCOのデータセットを構築
          li 非拘束（in the wild）の環境にてDensePoseを学習。
    .item4
      h1 自由記述欄
      .text
        ul
          li リアルが完全に崩壊した。（Face2Faceの全身モデル版が実現可能になった？）
          li CG/UIの分野との親和性がより高くなった
          li: a(href="https://arxiv.org/abs/1802.00434" target="blank") DensePose: Dense Human Pose Estimation In The Wild
          li: a(href="https://arxiv.org/abs/1612.01202" target="blank") DenseReg
          li: a(href="http://smpl.is.tue.mpg.de" target="blank") SMPL
          li: a(href="http://hirokatsukataoka.net/" target="blank") slide by Hirokatsu Kataoka
    .header
      | #{getPaperIndex()}