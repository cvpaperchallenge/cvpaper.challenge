+slide
section#Towards_Universal_Representation_for_Unseen_Action_Recognition
  .paper-abstract
    .title Towards Universal Representation for Unseen Action Recognition
    .info
      .authors Yi Zhu, Yang Long, Yu Guan, Shawn Newsam, Ling Shao
      .conference CVPR 2018
    .slide_editor: a(href="http://hirokatsukataoka.net/" target="blank") Hirokatsu Kataoka
  
    .item1
      .text
        h1 概要
        p 学習画像がなくても行動認識を実現する「Unseen Action Recognition (UAR)」についての研究。UARの問題をMIL（Multiple Instance Learning）の一般化（GMIL）として扱い、ActivityNetなど大規模動画データから分布推定して表現を獲得。図は提案手法であるCross-Domain UAR (CD-UAR)である。ビデオから抽出したDeep特徴はGMILによりカーネル化される。Word2Vecとの投稿によりURを獲得し、ドメイン変換により新しい概念を獲得する。
    .item2
      .text
        p
          img(src=`${figpath}180323UAR.png`,alt="180323UAR")
    .item3
      .text
        h1 新規性・結果
        p 従来法では見た/見てないの対応関係をデータセット中に含ませていたが、本論文での提案はUniversal Representation（ユニバーサル表現）を獲得して同タスクを解決する。
    .item4
      .text
        h1 リンク集
        ul
          li
            a(href="https://arxiv.org/pdf/1803.08460.pdf") 論文
    .slide_index #{getSlideIndex()}
    .timestamp 2018.3.23 19:40:06
