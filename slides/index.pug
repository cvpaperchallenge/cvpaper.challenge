extends layouts/_layout

block slides
  +slide
    .title Generating the Future with Adversarial Transformers
    .info C. Vondrick et al., CVPR, 2017.
    .item1
      h1 概要
      .text.
        未来の動画を予測して生成する手法を提案．
        4フレーム x 64画素 x 64画素のクリップを入力として，その後の16フレームの動画を生成．
        完全に新しいフレームを生成するのは難しいので，入力フレームの変換により未来のフレームを生成するのがポイント．
        論文の主張としては，きれいな動画を作るにはLow-Levelな情報が重要だけど，未来予測のためにはHigh-Levelな理解も必要で，
        その両者を一つのネットワークで一気に学習するのは難しいとしている．
        だから，Low-Levelな情報は元のフレームを変換することで引っ張ってきて，ネットワークはHigh-Levelな特徴抽出に集中させるのが良いとのこと．
        このネットワークの学習はGANベース．
        生成動画の主観評価や可視化，Generatorの特徴を利用した物体認識タスクなどで性能を評価．

    .item2
      img(src=figpath+"generating_future.png")
    .item3
      h1 新規性・結果
      .text
        ul
          li 元のフレームからの変換により未来のフレームを生成する手法を提案
          li 未来の動画生成において，敵対的学習により大規模な教師なしデータを利用した学習を実現
          li 直接動画を生成したり，回帰誤差で学習したりする手法よりも良いことを主観評価実験で確認          
    .item4
      h1 自由記述欄
      .text
        ul
          li 入力が4フレームだけだけど，もっと増やすと性能は変わるのか気になる
          li 主観評価で本物と比較すると提案手法が一番嫌われている率が高いのもちょっと気になる

  // slide2
  +slide
    .title DensePose: Dense Human Pose Estimation In The Wild
    .info Rıza Alp Guler et al., a(href="https://arxiv.org/pdf/1802.00434.pdf")
    .item1
      h1 概要
      .text.
        身体の表面形状まで考慮したDenseな姿勢推定手法に関する研究。サーフェイスモデルを提供するSMPLタイプとアノテーションベースのMSCOCOタイプを提供。手法はMask RCNN（w/ ResNet-50, ROI-align, Regression）をベースに構築している。

    .item2
      img(src=figpath+"180205densepose.png")
    .item3
      h1 新規性・結果
      .text
        ul
          li DenseReg [Guler,CVPR17]は顔表面の推定に対して、本研究では身体全体の表面やデンスなポイントを回帰。
          li SMPLやDense-COCOのデータセットを構築
          li 非拘束（in the wild）の環境にてDensePoseを学習。     
    .item4
      h1 自由記述欄
      .text
        ul
          li リアルが完全に崩壊した。（Face2Faceの全身モデル版が実現可能になった？）
          li CG/UIの分野との親和性がより高くなった
          li <a href="https://twitter.com/hirokatukataoka">Hirokatsu Kataoka</a>