extends layouts/_layout

block slides
  +slide
    .title Generating the Future with Adversarial Transformers
    .info C. Vondrick et al., CVPR, 2017.
    .item1
      h1 概要
      .text.
        未来の動画を予測して生成する手法を提案．
        4フレーム x 64画素 x 64画素のクリップを入力として，その後の16フレームの動画を生成．
        完全に新しいフレームを生成するのは難しいので，入力フレームの変換により未来のフレームを生成するのがポイント．
        もっともらしい動画を作るにはLow-Levelな情報が重要になるものの，予測のためにはHigh-Levelな理解も必要であり，
        その両者を一気に一つのネットワークで学習するのは難しいので，
        Low-Levelな情報は元のフレームを変換することで引っ張ってきて，ネットワークはHigh-Levelな特徴抽出に集中させるのが良いと主張．
        このような変換を実現するためにTransformerという機構を取り入れたアーキテクチャを提案．
        このネットワークの学習には，敵対的学習を利用しており，本物の動画か生成した動画かを識別するDiscriminatorと同時に学習をしている．
        生成動画の主観評価や可視化，Generatorの特徴を利用した物体認識タスクなどで性能を評価．

    .item2
      img(src=figpath+"generating_future.png")
    .item3
      h1 新規性・結果
      .text
        ul
          li 元のフレームからの変換により未来のフレームを生成する手法を提案
          li 未来の動画生成において，敵対的学習により大規模な教師なしデータを利用した学習を実現
          li 直接動画を生成したり，回帰誤差で学習したりする手法よりも良いことを主観評価実験で確認          
    .item4
      h1 自由記述欄
      .text
        ul
          li 入力が4フレームだけだけど，もっと増やすと性能は変わるのか気になる
          li 主観評価で本物と比較すると提案手法が一番嫌われている率が高いのもちょっと気になる
