+slide
  .title AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection
  .info
    .authors Thanh-Toan Do, Anh Nguyen, Ian Reid, Darwin G. Caldwell, Nikos G. Tsagarakis
    .conference ICRA 2018
  .slide_editor: a(href="http://hirokatsukataoka.net/" target="blank") Hirokatsu Kataoka

  .item1
    .text
      h1 概要
      p 物体検出とアフォーダンス（というよりは機能？）のセグメントを同時に回帰するネットワーク、AffordanceNetに関する論文。ロボットへの把持位置/機能教示を行うことができる。基本的なモデルはMask R-CNNを適用していて、物体検出のためのbboxと物体に対する機能セグメントを正解として学習する。多タスクの誤差関数は物体カテゴリ、座標、機能セグメントの3つに関するものである。
  .item2
    .text
      p
        img(src=`${figpath}180302AffordanceNet.png`,alt="180302AffordanceNet")
  .item3
    .text
      h1 新規性・結果
      p 従来、物体検知と機能推定は別個に学習・認識されていたが、本研究では多タスク学習の枠組みで、単一モデルにてEnd-to-End学習した。IIT-AFF Datasetにて73.35（SoTAは69.62）、UMD Datasetにて79.9（SoTAは77.0）。モデルも公開されており、誰もがAffordanceNetを実装できるようにしている。
  .item4
    .text
      h1 コメント・リンク集
      p 任意のセグメンテーションラベルさえあれば、物体検知とあらゆる高次なセグメンテーションモデルが実現可能となった。
      ul
        li
          a(href="https://arxiv.org/pdf/1709.07326.pdf") 論文
        li
          a(href="https://github.com/nqanh/affordance-net") GitHub
  .slide_index #{getSlideIndex()}
  .timestamp 2018.3.2 20:38:13

