+slide
section#ID_Vision-based_Engagement_Detection_in_Virtual_Reality
  .paper-abstract
    .title Vision-based Engagement Detection in Virtual Reality
    .info
      .authors Ghassem Tofighi, Kaamraan Raahemifar, Maria Frank, Haisong Gu
      .paper_id 1609.01344
    .slide_editor ShusukeShigenaka
  
    .item1
      .text
        h1 概要
        p ビジョンベースのインタフェースにおけるユーザの精神状態検出は最も重要な研究の1つである．本研究は4つの異なる状態を有する有限状態変換器(FST)を使用したフレームベースの精神状態検出システムを提案．カメラセンサを使用した2Dおよび3Dの仮想現実の画像データから,素早く,そして正確にユーザの精神状態（エンゲージメント）を知ることができる．
    .item2
      .text
        p
          img(src=`${figpath}Vision-based_Engagement_Detection_in_Virtual_Reality.png`,alt="Vision-based_Engagement_Detection_in_Virtual_Reality.png")
    .item3
      .text
        h1 新規性
        p 非言語の動きの分類のデータと精神状態の指標を組み合わせることで精神状態（エンゲージメント）を量子的に表示．
    .item4
      .text
        h1 結果・リンク集
        p 提案手法のラベル付けのパフォーマンスは4つの合計平均で92.3%の精度である．さらに各フレームの処理時間は10ms未満であることからアルゴリズムのリアルタイム性も示している．
        ul
          li
            a(href="https://arxiv.org/abs/1609.01344") link1
    .slide_index #{getSlideIndex()}
    .timestamp 2018.4.19 13:57:11

