+slide
section#Generating_the_Future_with_Adversarial_Transformers
  .paper-abstract
    .title Generating the Future with Adversarial Transformers
    .info
      .authors C. Vondrick et al.,
      .conference CVPR, 2017.
    .item1
      h1 概要
      .text.
        未来の動画を予測して生成する手法を提案．
        4フレーム x 64画素 x 64画素のクリップを入力として，その後の16フレームの動画を生成．
        完全に新しいフレームを生成するのは難しいので，入力フレームの変換により未来のフレームを生成するのがポイント．
        論文の主張としては，きれいな動画を作るにはLow-Levelな情報が重要だけど，未来予測のためにはHigh-Levelな理解も必要で，
        その両者を一つのネットワークで一気に学習するのは難しいとしている．
        だから，Low-Levelな情報は元のフレームを変換することで引っ張ってきて，ネットワークはHigh-Levelな特徴抽出に集中させるのが良いとのこと．
        このネットワークの学習はGANベース．
        生成動画の主観評価や可視化，Generatorの特徴を利用した物体認識タスクなどで性能を評価．
  
    .item2
      img(src=figpath+"generating_future.png")
    .item3
      h1 新規性・結果
      .text
        ul
          li 元のフレームからの変換により未来のフレームを生成する手法を提案
          li 未来の動画生成において，敵対的学習により大規模な教師なしデータを利用した学習を実現
          li 直接動画を生成したり，回帰誤差で学習したりする手法よりも良いことを主観評価実験で確認          
    .item4
      h1 自由記述欄
      .text
        ul
          li 入力が4フレームだけだけど，もっと増やすと性能は変わるのか気になる
          li 主観評価で本物と比較すると提案手法が一番嫌われている率が高いのもちょっと気になる
    .slide_index
      | #{getSlideIndex()}
    .slide_editor Kensho Hara
